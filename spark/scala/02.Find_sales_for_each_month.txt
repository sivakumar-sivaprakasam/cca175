#To find sales for each month, we need to join orders & order_items dataset
#order_items dataset has sales for each order, orders dataset having order_date
#To find month, we can use substring to get year & month

#Transformations used in this use-case: Map, Join, ReduceByKey, SortByKey
#Actions used in this use-case: Take, ForEach, SaveAsTextFile

####################### Using scala #############################################
val ordersRDD = sc.textFile("/home/cloudera/orders.txt")
val orderItemsRDD = sc.textFile("/home/cloudera/order_items.txt")

#creating tuple object with order_id and year and month from order_date
val ordersMap = ordersRDD.map(x => x.split(",")).map(x => (x(0).toInt, x(1).substring(0, 7)))

#creating tuple object having order_id as key and bill amount as value
val orderItemsMap = orderItemsRDD.map(x => x.split(",")).map(x => (x(1).toInt, x(4).toFloat))

#joining orders with orderitems
val ordersJoin = ordersMap.join(orderItemsMap)

#Forming another Tuple object having order month as key and bill amount as value
val orderSalesMap = ordersJoin.map(x => (x._2._1, x._2._2))

#using reduceByKey to find total sales for each month and then sorted it 
val totalSalesPerMonth = orderSalesMap.reduceByKey((a, b) => (a + b)).sortByKey()

totalSalesPerMonth.foreach(println)

#Saving the output into orderSalesPerMonth directory
#It is important to make sure the target folder doesn't exists
#If it exists, this method will fail
totalSalesPerMonth.saveAsTextFile("/home/cloudera/orderSalesPerMonth")

####################### Using spark-sql (SQLContext) ############################
import org.apache.spark.sql.{SQLContext, Row}

val sqlContext = new SQLContext(sc)

sqlContext.sql("set spark.sql.shuffle.partitions=10")

case class Orders(order_id: Int, order_date: String)

case class OrderItems(order_item_order_id: Int, order_item_subtotal: Float)

val ordersMap = sc.textFile("/home/cloudera/orders.txt").map(x => x.split(",")).map(x => Orders(x(0).toInt, x(1).substring(0, 7)))

val orderItemsMap = sc.textFile("/home/cloudera/order_items.txt").map(x => x.split(",")).map(x => OrderItems(x(1).toInt, x(4).toFloat))

import sqlContext.createSchemaRDD

ordersMap.registerTempTable("OrdersTbl")

orderItemsMap.registerTempTable("OrderItemsTbl")

val totalSalesPerMonth = sqlContext.sql("select o.order_date, sum(oi.order_item_subtotal) from OrdersTbl o join OrderItemsTbl oi on o.order_id=oi.order_item_order_id group by o.order_date order by o.order_date")

totalSalesPerMonth.take(5).foreach(println)

####################### Using Hive (HiveContext) ####################################
#Pre-requisites: Table must be exists in Hive
import org.apache.spark.sql.hive.HiveContext

val sqlContext = new HiveContext(sc)

sqlContext.sql("set spark.sql.shuffle.partitions=10")

sqlContext.sql("use retail_db")

val totalSalesPerMonth = sqlContext.sql("select substring(o.order_date, 1, 7), sum(oi.order_item_subtotal) from orders o join order_items oi on o.order_id=oi.order_item_order_id group by substring(o.order_date, 1, 7) order by substring(o.order_date, 1, 7)")

totalSalesPerMonth.take(5).foreach(println)

#Validation Script (Using Sqoop Eval)
sqoop eval \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--query "select substring(o.order_date, 1, 7) odate, sum(oi.order_item_subtotal) from orders o join order_items oi on o.order_id=oi.order_item_order_id group by odate order by odate"

